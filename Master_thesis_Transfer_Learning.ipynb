{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Master-thesis---Transfer-Learning",
      "provenance": [],
      "authorship_tag": "ABX9TyOZNdSWm7xki7NBRN+ZyL7d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thanospapastef/Master-thesis---Transfer-Learning/blob/main/Master_thesis_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_L73nS5hJj2"
      },
      "outputs": [],
      "source": [
        "#importing libraries\n",
        "!pip3 install opencv-python\n",
        "import cv2\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os\n",
        "from scipy import stats as s\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#downloading and extracting UCF-101 dataset\n",
        "!wget -nc --no-check-certificate https://www.crcv.ucf.edu/data/UCF101/UCF101.rar\n",
        "!unrar e UCF101.rar Videos/"
      ],
      "metadata": {
        "id": "If-3RnOyhUHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating train and test datasets according to authors of UCF-101 (i.e. appropriate dataset split) \n",
        "f = open(\"trainlist01.txt\", \"r\")\n",
        "temp = f.read()\n",
        "videos = temp.split('\\n')\n",
        "train = pd.DataFrame()\n",
        "train['video_name'] = videos\n",
        "train = train[:-1]\n",
        "train.shape\n",
        "\n",
        "f = open(\"testlist01.txt\", \"r\")\n",
        "temp = f.read()\n",
        "videos = temp.split('\\n')\n",
        "test = pd.DataFrame()\n",
        "test['video_name'] = videos\n",
        "test = test[:-1]\n",
        "test_videos = test['video_name']\n",
        "test.shape\n",
        "\n",
        "train_video_tag = []\n",
        "\n",
        "for i in range(train.shape[0]):\n",
        "  train_video_tag.append(train['video_name'][i].split('/')[0])\n",
        "\n",
        "train['tag'] = train_video_tag\n",
        "\n",
        "test_video_tag = []\n",
        "\n",
        "for i in range(test.shape[0]):\n",
        "  test_video_tag.append(test['video_name'][i].split('/')[0])\n",
        "\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "    count = 0\n",
        "    videoFile = train['video_name'][i]\n",
        "    cap = cv2.VideoCapture('Videos/'+videoFile.split(' ')[0].split('/')[1])\n",
        "    frameRate = cap.get(5)\n",
        "\n",
        "    while(cap.isOpened()):\n",
        "        frameId = cap.get(1)\n",
        "        ret, frame = cap.read()\n",
        "        if (ret != True):\n",
        "            break\n",
        "        if (frameId % math.floor(frameRate) == 0):\n",
        "\n",
        "# storing the frames in a new folder named train_1\n",
        "            filename ='train_1/' +\n",
        "            videoFile.split('/')[1].split(' ')[0]+\n",
        "            \"_frame%d.jpg\" % count;count+=1\n",
        "            cv2.imwrite(filename, frame)\n",
        "    cap.release()\n",
        "images = glob(\"train_1/*.jpg\")\n",
        "train_image = []\n",
        "train_class = []\n",
        "\n",
        "for i in tqdm(range(len(images))):\n",
        "\n",
        "    train_image.append(images[i].split('/')[1])\n",
        "\n",
        "    train_class.append(images[i].split('/')[1].split('_')[1])\n",
        "\n",
        "train_data = pd.DataFrame()\n",
        "train_data['image'] = train_image\n",
        "train_data['class'] = train_class\n",
        "\n",
        "train_data.to_csv('Videos/train_new.csv',header=True, index=False)\n",
        "\n",
        "train = pd.read_csv('Videos/train_new.csv')\n",
        "\n",
        "images = glob(\"train_1/*.jpg\")\n",
        "train_image = []\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "    img = image.load_img('train_1/'+train['image'][i], target_size=(224,224,3))\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255\n",
        "    train_image.append(img)\n",
        "X = np.array(train_image)\n",
        "X.shape\n",
        "\n",
        "y = train['class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "random_state=42, test_size=0.2, stratify = y)\n",
        "\n",
        "y_train = pd.get_dummies(y_train)\n",
        "y_test = pd.get_dummies(y_test)\n",
        "y = pd.get_dummies(y)\n",
        "\n",
        "shape = (224, 224, 3)\n",
        "\n",
        "base_model_1 = tf.keras.applications.VGG16(weights='imagenet',\n",
        "include_top=False, input_shape=shape)\n",
        "\n",
        "base_model_2 = tf.keras.applications.InceptionV3(weights='imagenet',\n",
        "include_top=False, input_shape=shape)\n",
        "\n",
        "base_model_3 = tf.keras.applications.Xception(weights='imagenet',\n",
        "include_top=False, input_shape=shape)\n",
        "\n",
        "X_train_VGG16 = base_model_1.predict(X_train)\n",
        "X_train_VGG16.shape\n",
        "\n",
        "X_test_VGG16 = base_model_1.predict(X_test)\n",
        "X_test_VGG16.shape\n",
        "\n",
        "X_train_InceptionV3 = base_model_2.predict(X_train)\n",
        "X_train_InceptionV3.shape\n",
        "\n",
        "X_test_InceptionV3 = base_model_2.predict(X_test)\n",
        "X_test_InceptionV3.shape\n",
        "\n",
        "X_train_Xception = base_model_3.predict(X_train)\n",
        "X_train_Xception.shape\n",
        "\n",
        "X_test_Xception = base_model_3.predict(X_test)\n",
        "X_test_Xception.shape\n",
        "\n",
        "X_train_VGG16 = X_train_VGG16.reshape(59075, 7*7*512)\n",
        "X_test_VGG16 = X_test_VGG16.reshape(14769, 7*7*512)\n",
        "\n",
        "X_train_InceptionV3 = X_train_InceptionV3.reshape(59075, 5*5*2048)\n",
        "X_test_InceptionV3 = X_test_InceptionV3.reshape(14769, 5*5*2048)\n",
        "\n",
        "X_train_Xception = X_train_Xception.reshape(59075, 7*7*2048)\n",
        "X_test_Xception = X_test_Xception.reshape(14769, 7*7*2048)\n",
        "\n",
        "max = X_train_VGG16.max()\n",
        "X_train_VGG16 = X_train_VGG16/max\n",
        "X_test_VGG16 = X_test_VGG16/max\n",
        "\n",
        "max = X_train_InceptionV3.max()\n",
        "X_train_InceptionV3 = X_train_InceptionV3/max\n",
        "X_test_InceptionV3 = X_test_InceptionV3/max\n",
        "\n",
        "max = X_train_Xception.max()\n",
        "X_train_Xception = X_train_Xception/max\n",
        "X_test_Xception = X_test_Xception/max"
      ],
      "metadata": {
        "id": "8YnUKHjChXOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = Sequential()\n",
        "model_1.add(Dense(1024, activation='relu', input_shape=(25088,)))\n",
        "model_1.add(Dropout(0.5))\n",
        "model_1.add(Dense(512, activation='relu'))\n",
        "model_1.add(Dropout(0.5))\n",
        "model_1.add(Dense(256, activation='relu'))\n",
        "model_1.add(Dropout(0.5))\n",
        "model_1.add(Dense(128, activation='relu'))\n",
        "model_1.add(Dropout(0.5))\n",
        "model_1.add(Dense(101, activation='softmax'))\n",
        "\n",
        "model_2 = Sequential()\n",
        "model_2.add(Dense(1024, activation='relu', input_shape=(51200,)))\n",
        "model_2.add(Dropout(0.5))\n",
        "model_2.add(Dense(512, activation='relu'))\n",
        "model_2.add(Dropout(0.5))\n",
        "model_2.add(Dense(256, activation='relu'))\n",
        "model_2.add(Dropout(0.5))\n",
        "model_2.add(Dense(128, activation='relu'))\n",
        "model_2.add(Dropout(0.5))\n",
        "model_2.add(Dense(101, activation='softmax'))\n",
        "\n",
        "model_3 = Sequential()\n",
        "model_3.add(Dense(1024, activation='relu', input_shape=(100352,)))\n",
        "model_3.add(Dropout(0.5))\n",
        "model_3.add(Dense(512, activation='relu'))\n",
        "model_3.add(Dropout(0.5))\n",
        "model_3.add(Dense(256, activation='relu'))\n",
        "model_3.add(Dropout(0.5))\n",
        "model_3.add(Dense(128, activation='relu'))\n",
        "model_3.add(Dropout(0.5))\n",
        "model_3.add(Dense(101, activation='softmax'))\n",
        "\n",
        "model_1.compile(loss='categorical_crossentropy',optimizer='Adam',\n",
        "metrics=['accuracy'])\n",
        "\n",
        "model_2.compile(loss='categorical_crossentropy',optimizer='Adam',\n",
        "metrics=['accuracy'])\n",
        "\n",
        "model_3.compile(loss='categorical_crossentropy',optimizer='Adam',\n",
        "metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "WKuRBroChbLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcp_save_1 = ModelCheckpoint('VGG16.hdf5', save_best_only=True,\n",
        "monitor='val_loss', mode='min')\n",
        "\n",
        "# training the model\n",
        "model_training_history_1 = model_1.fit(X_train_VGG16, y_train, epochs=100,\n",
        "validation_data=(X_test_VGG16, y_test), callbacks = mcp_save_1,\n",
        "batch_size=128)\n",
        "\n",
        "def plot_metric(metric_name_1, metric_name_2, plot_name):\n",
        "\n",
        "    # Get Metric values using metric names as identifiers\n",
        "    metric_value_1 = model_training_history_1.history[metric_name_1]\n",
        "    metric_value_2 = model_training_history_1.history[metric_name_2]\n",
        "\n",
        "    # Constructing a range object which will be used as time\n",
        "    epochs = range(len(metric_value_1))\n",
        "\n",
        "    # Plotting the Graph\n",
        "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
        "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
        "\n",
        "    # Adding title to the plot\n",
        "    plt.title(str(plot_name))\n",
        "\n",
        "    # Adding legend to the plot\n",
        "    plt.legend()\n",
        "\n",
        "plot_metric('loss', 'val_loss', 'Total Loss vs Total Validation Loss')\n",
        "plot_metric('accuracy', 'val_accuracy', 'Total Accuracy vs\n",
        "Total Validation Accuracy')"
      ],
      "metadata": {
        "id": "EhgQcmzZhiWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcp_save_2 = ModelCheckpoint('InceptionV3.hdf5', save_best_only=True,\n",
        "monitor='val_loss', mode='min')\n",
        "\n",
        "# training the model\n",
        "model_training_history_2 = model_2.fit(X_train_InceptionV3, y_train, epochs=100,\n",
        "validation_data=(X_test_InceptionV3, y_test), callbacks = mcp_save_2,\n",
        "batch_size=128)\n",
        "\n",
        "def plot_metric(metric_name_1, metric_name_2, plot_name):\n",
        "\n",
        "    # Get Metric values using metric names as identifiers\n",
        "    metric_value_1 = model_training_history_2.history[metric_name_1]\n",
        "    metric_value_2 = model_training_history_2.history[metric_name_2]\n",
        "\n",
        "    # Constructing a range object which will be used as time\n",
        "    epochs = range(len(metric_value_1))\n",
        "\n",
        "    # Plotting the Graph\n",
        "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
        "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
        "\n",
        "    # Adding title to the plot\n",
        "    plt.title(str(plot_name))\n",
        "\n",
        "    # Adding legend to the plot\n",
        "    plt.legend()\n",
        "plot_metric('loss', 'val_loss', 'Total Loss vs Total Validation Loss')\n",
        "plot_metric('accuracy', 'val_accuracy', 'Total Accuracy vs\n",
        "Total Validation Accuracy')"
      ],
      "metadata": {
        "id": "--Ipx8VOhr2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcp_save_3 = ModelCheckpoint('Xception.hdf5', save_best_only=True,\n",
        "monitor='val_loss', mode='min')\n",
        "\n",
        "# training the model\n",
        "model_training_history_3 = model_3.fit(X_train_Xception, y_train, epochs=100,\n",
        "validation_data=(X_test_Xception, y_test), callbacks = mcp_save_3,\n",
        "batch_size=128)\n",
        "\n",
        "def plot_metric(metric_name_1, metric_name_2, plot_name):\n",
        "\n",
        "    # Get Metric values using metric names as identifiers\n",
        "    metric_value_1 = model_training_history_3.history[metric_name_1]\n",
        "    metric_value_2 = model_training_history_3.history[metric_name_2]\n",
        "\n",
        "    # Constructing a range object which will be used as time\n",
        "    epochs = range(len(metric_value_1))\n",
        "\n",
        "    # Plotting the Graph\n",
        "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
        "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
        "\n",
        "    # Adding title to the plot\n",
        "    plt.title(str(plot_name))\n",
        "\n",
        "    # Adding legend to the plot\n",
        "    plt.legend()\n",
        "plot_metric('loss', 'val_loss', 'Total Loss vs Total Validation Loss')\n",
        "plot_metric('accuracy', 'val_accuracy', 'Total Accuracy vs\n",
        "Total Validation Accuracy')"
      ],
      "metadata": {
        "id": "3h4CA-Hkh5rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_1 = []\n",
        "predict_2 = []\n",
        "predict_3 = []\n",
        "actual = []\n",
        "\n",
        "for i in tqdm(range(test_videos.shape[0])):\n",
        "    count = 0\n",
        "    videoFile = test_videos[i]\n",
        "    cap = cv2.VideoCapture('Videos/'+videoFile.split(' ')[0].split('/')[1])\n",
        "    frameRate = cap.get(5) #frame rate\n",
        "\n",
        "    # removing all other files from the temp folder\n",
        "    files = glob('temp/*')\n",
        "    for f in files:\n",
        "        os.remove(f)\n",
        "    while(cap.isOpened()):\n",
        "        frameId = cap.get(1) #current frame number\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if (ret != True):\n",
        "          break\n",
        "\n",
        "        if (frameId % math.floor(frameRate) == 0):\n",
        "          filename ='temp/' + \"_frame%d.jpg\" % count;count+=1\n",
        "          cv2.imwrite(filename, frame)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # reading all the frames from temp folder\n",
        "    images = glob(\"temp/*.jpg\")\n",
        "\n",
        "    prediction_images = []\n",
        "    for i in range(len(images)):\n",
        "        img = image.load_img(images[i], target_size=(224,224,3))\n",
        "        img = image.img_to_array(img)\n",
        "        img = img/255\n",
        "        prediction_images.append(img)\n",
        "\n",
        "    # converting all the frames for a test video into numpy array\n",
        "    prediction_images = np.array(prediction_images)\n",
        "\n",
        "    # extracting features using pre-trained model\n",
        "    prediction_images_1 = base_model_1.predict(prediction_images)\n",
        "    prediction_images_2 = base_model_2.predict(prediction_images)\n",
        "    prediction_images_3 = base_model_3.predict(prediction_images)\n",
        "\n",
        "    # converting features in one dimensional array\n",
        "    # do the same for each model\n",
        "    prediction_images_1 = prediction_images_1.reshape(\n",
        "    prediction_images_1.shape[0],\n",
        "    7*7*512)\n",
        "\n",
        "    prediction_images_2 = prediction_images_2.reshape(\n",
        "    prediction_images_2.shape[0],\n",
        "    5*5*2048)\n",
        "    \n",
        "    prediction_images_3 = prediction_images_3.reshape(\n",
        "    prediction_images_3.shape[0],\n",
        "    7*7*2048)\n",
        "\n",
        "    # predicting tags for each array\n",
        "    prediction_1 = np.argmax(model_1.predict(prediction_images_1), axis=1)\n",
        "    prediction_2 = np.argmax(model_2.predict(prediction_images_2), axis=1)\n",
        "    prediction_3 = np.argmax(model_3.predict(prediction_images_3), axis=1)\n",
        "\n",
        "    # appending the mode of predictions in predict lists to assign the\n",
        "    # tag to the video,\n",
        "    # do the same for each model\n",
        "    predict_1.append(y.columns.values[s.mode(prediction_1)[0][0]])\n",
        "    predict_2.append(y.columns.values[s.mode(prediction_2)[0][0]])\n",
        "    predict_3.append(y.columns.values[s.mode(prediction_3)[0][0]])\n",
        "\n",
        "    # appending the actual tag of the video\n",
        "    actual.append(videoFile.split('/')[1].split('_')[1])\n",
        "\n",
        "#prediction scores from each model\n",
        "accuracy_score(predict_1, actual)*100\n",
        "accuracy_score(predict_2, actual)*100\n",
        "accuracy_score(predict_3, actual)*100"
      ],
      "metadata": {
        "id": "6APkpOCYh7L5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}